{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dx7vrTxEgiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKjWlP7LFJow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('anna.txt','r') as f:\n",
        "  text=f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcLL_F8RFgWD",
        "colab_type": "code",
        "outputId": "92a3f946-1022-490f-f699-a6f8a39df3a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "text[:100]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Chapter 1\\n\\n\\nHappy families are all alike; every unhappy family is unhappy in its own\\nway.\\n\\nEverythin'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZzMY-q3FjRS",
        "colab_type": "code",
        "outputId": "b8022106-35d9-4afe-ad02-b4ebf39ced75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "char = tuple(set(text))\n",
        "int2char=dict(enumerate(char))\n",
        "char2int={ch:li for li,ch in int2char.items() }\n",
        "print(char2int)\n",
        "encoded = np.array([char2int[ch] for ch in text])\n",
        "encoded[:100]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'W': 0, ' ': 1, 'v': 2, 'g': 3, 'P': 4, '2': 5, 'y': 6, 'c': 7, 'r': 8, 'C': 9, '7': 10, 's': 11, '9': 12, 'i': 13, '(': 14, 'X': 15, '%': 16, 'K': 17, \"'\": 18, 'A': 19, 'k': 20, 'l': 21, 'U': 22, '4': 23, 'R': 24, 't': 25, 'F': 26, 'o': 27, 'S': 28, '_': 29, 'H': 30, '3': 31, 'n': 32, 'Y': 33, '/': 34, '@': 35, 'N': 36, 'm': 37, 'e': 38, 'O': 39, '1': 40, 'j': 41, 'Z': 42, '8': 43, '*': 44, '5': 45, '$': 46, 'Q': 47, '`': 48, '.': 49, 'G': 50, 'u': 51, 'a': 52, ';': 53, ')': 54, '!': 55, '-': 56, '&': 57, 'x': 58, 'z': 59, 'b': 60, 'T': 61, '\\n': 62, 'q': 63, '\"': 64, 'I': 65, ':': 66, '6': 67, '0': 68, 'd': 69, 'h': 70, 'p': 71, 'f': 72, ',': 73, 'D': 74, 'B': 75, 'L': 76, 'M': 77, 'J': 78, 'E': 79, '?': 80, 'w': 81, 'V': 82}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 9, 70, 52, 71, 25, 38,  8,  1, 40, 62, 62, 62, 30, 52, 71, 71,  6,\n",
              "        1, 72, 52, 37, 13, 21, 13, 38, 11,  1, 52,  8, 38,  1, 52, 21, 21,\n",
              "        1, 52, 21, 13, 20, 38, 53,  1, 38,  2, 38,  8,  6,  1, 51, 32, 70,\n",
              "       52, 71, 71,  6,  1, 72, 52, 37, 13, 21,  6,  1, 13, 11,  1, 51, 32,\n",
              "       70, 52, 71, 71,  6,  1, 13, 32,  1, 13, 25, 11,  1, 27, 81, 32, 62,\n",
              "       81, 52,  6, 49, 62, 62, 79,  2, 38,  8,  6, 25, 70, 13, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8TsaOvXHJfI",
        "colab_type": "code",
        "outputId": "ff4d3672-d503-4ac2-a26f-a45d9ad7dba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "def one_hot_encode(arr,n_labels):\n",
        "  one_hot = np.zeros((arr.size, n_labels), dtype=np.float32)\n",
        "  one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1\n",
        "  one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
        "    \n",
        "  return one_hot\n",
        "def one_hot_encod(arr, n_labels):\n",
        "  one_hot = np.zeros((arr.size, n_labels), dtype=np.float32)\n",
        "  one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
        "  one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
        "  return one_hot  \n",
        "\n",
        "\n",
        "test_seq = np.array([[3, 5, 1]])\n",
        "print(test_seq.size)\n",
        "one_hot = one_hot_encod(test_seq, 8)\n",
        "\n",
        "print(one_hot)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "[[[0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0.]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkUqTYwDrh0p",
        "colab_type": "code",
        "outputId": "5d756e8f-af2f-41b9-9bc9-afc06bfa5186",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "def get_batches(arr, batch_size, seq_length):\n",
        "    '''Create a generator that returns batches of size\n",
        "       batch_size x seq_length from arr.\n",
        "       \n",
        "       Arguments\n",
        "       ---------\n",
        "       arr: Array you want to make batches from\n",
        "       batch_size: Batch size, the number of sequences per batch\n",
        "       seq_length: Number of encoded chars in a sequence\n",
        "    '''\n",
        "    \n",
        "    batch_size_total = batch_size * seq_length\n",
        "    # total number of batches we can make\n",
        "    n_batches = len(arr)//batch_size_total\n",
        "    \n",
        "    # Keep only enough characters to make full batches\n",
        "    arr = arr[:n_batches * batch_size_total]\n",
        "    # Reshape into batch_size rows\n",
        "    arr = arr.reshape((batch_size, -1))\n",
        "    \n",
        "    # iterate through the array, one sequence at a time\n",
        "    for n in range(0, arr.shape[1], seq_length):\n",
        "        # The features\n",
        "        x = arr[:, n:n+seq_length]\n",
        "        # The targets, shifted by one\n",
        "        y = np.zeros_like(x)\n",
        "        try:\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+seq_length]\n",
        "        except IndexError:\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
        "        yield x, y\n",
        "\n",
        "\n",
        "batches = get_batches(encoded, 8, 50)\n",
        "x, y = next(batches) \n",
        "print('x\\n', x)\n",
        "print('\\ny\\n', y) \n",
        "print(len(encoded))      "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x\n",
            " [[ 9 70 52 71 25 38  8  1 40 62 62 62 30 52 71 71  6  1 72 52 37 13 21 13\n",
            "  38 11  1 52  8 38  1 52 21 21  1 52 21 13 20 38 53  1 38  2 38  8  6  1\n",
            "  51 32]\n",
            " [11 27 32  1 25 70 52 25  1 52 25 25  8 52  7 25 38 69  1 70 38  8  1 52\n",
            "  25 25 38 32 25 13 27 32  1 81 52 11  1 70 38  8  1 70 51 11 60 52 32 69\n",
            "  49  1]\n",
            " [38 32 69  1 27  8  1 52  1 72 27 38 73  1 70 38  1 52  2 27 13 69 38 69\n",
            "   1 70 13 11  1 72 52 25 70 38  8 49  1 30 38 62 21 27 27 20 38 69  1  8\n",
            "  27 51]\n",
            " [11  1 25 70 38  1  7 70 13 38 72  1 25 70 27 51  3 70  1 70 13 69 69 38\n",
            "  32 62 13 32 25 38  8 38 11 25  1 27 72  1 70 13 11  1 21 13 72 38 73  1\n",
            "  27 72]\n",
            " [ 1 11 52 81  1 70 38  8  1 25 38 52  8 56 11 25 52 13 32 38 69 73  1 71\n",
            "  13 25 13 72 51 21 73  1 11 81 38 38 25  1 72 52  7 38 73 62 37 13 11 38\n",
            "   8 52]\n",
            " [ 7 51 11 11 13 27 32  1 52 32 69  1 52 32 52 21  6 11 13 11 73  1 81 52\n",
            "  11  1 13 32  1 71  8 13 32  7 13 71 21 38  1 69 13 11 52  3  8 38 38 52\n",
            "  60 21]\n",
            " [ 1 19 32 32 52  1 70 52 69  1 11 52 13 69  1 25 70 52 25  1 74 27 21 21\n",
            "   6  1 81 27 51 21 69  1 38 58  7 51 11 38  1 13 25 49  1 19 32 69  1 25\n",
            "  70 13]\n",
            " [39 60 21 27 32 11 20  6 49  1 64 75 51 25  1 29 25 70 38  6 29  1  7 52\n",
            "  32 32 27 25  1  3  8 52 11 71  1 25 70 52 25 73 62 29 25 70 38  6 29  1\n",
            "  52  8]]\n",
            "\n",
            "y\n",
            " [[70 52 71 25 38  8  1 40 62 62 62 30 52 71 71  6  1 72 52 37 13 21 13 38\n",
            "  11  1 52  8 38  1 52 21 21  1 52 21 13 20 38 53  1 38  2 38  8  6  1 51\n",
            "  32 70]\n",
            " [27 32  1 25 70 52 25  1 52 25 25  8 52  7 25 38 69  1 70 38  8  1 52 25\n",
            "  25 38 32 25 13 27 32  1 81 52 11  1 70 38  8  1 70 51 11 60 52 32 69 49\n",
            "   1 64]\n",
            " [32 69  1 27  8  1 52  1 72 27 38 73  1 70 38  1 52  2 27 13 69 38 69  1\n",
            "  70 13 11  1 72 52 25 70 38  8 49  1 30 38 62 21 27 27 20 38 69  1  8 27\n",
            "  51 32]\n",
            " [ 1 25 70 38  1  7 70 13 38 72  1 25 70 27 51  3 70  1 70 13 69 69 38 32\n",
            "  62 13 32 25 38  8 38 11 25  1 27 72  1 70 13 11  1 21 13 72 38 73  1 27\n",
            "  72  1]\n",
            " [11 52 81  1 70 38  8  1 25 38 52  8 56 11 25 52 13 32 38 69 73  1 71 13\n",
            "  25 13 72 51 21 73  1 11 81 38 38 25  1 72 52  7 38 73 62 37 13 11 38  8\n",
            "  52 60]\n",
            " [51 11 11 13 27 32  1 52 32 69  1 52 32 52 21  6 11 13 11 73  1 81 52 11\n",
            "   1 13 32  1 71  8 13 32  7 13 71 21 38  1 69 13 11 52  3  8 38 38 52 60\n",
            "  21 38]\n",
            " [19 32 32 52  1 70 52 69  1 11 52 13 69  1 25 70 52 25  1 74 27 21 21  6\n",
            "   1 81 27 51 21 69  1 38 58  7 51 11 38  1 13 25 49  1 19 32 69  1 25 70\n",
            "  13 11]\n",
            " [60 21 27 32 11 20  6 49  1 64 75 51 25  1 29 25 70 38  6 29  1  7 52 32\n",
            "  32 27 25  1  3  8 52 11 71  1 25 70 52 25 73 62 29 25 70 38  6 29  1 52\n",
            "   8 38]]\n",
            "1985223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ialR3SrismNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__ (self,token,hidden = 256,n_layers=2,drop_pb =0.5 ,lr=0.001):\n",
        "    super(). __init__ ()\n",
        "    self.hidden=hidden\n",
        "    self.n_layers =n_layers\n",
        "    self.drop_pb =drop_pb\n",
        "    self.lr=lr\n",
        "\n",
        "    self.char=token\n",
        "    self.int2char = dict(enumerate(self.char))\n",
        "    self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
        "\n",
        "\n",
        "    self.lstm=nn.LSTM(len(self.char), hidden,n_layers,batch_first=True,dropout=drop_pb)\n",
        "    self.dropout=nn.Dropout(p=drop_pb)\n",
        "    self.fc = nn.Linear(hidden,len(self.char))\n",
        "\n",
        "\n",
        "  def forward(self,x,hidden):\n",
        "\n",
        "\n",
        "    output,hidden=self.lstm(x,hidden)\n",
        "    out=self.dropout(output)\n",
        "    out=out.contiguous().view(-1,self.hidden)\n",
        "    out = self.fc(out)\n",
        "\n",
        "    return out,hidden\n",
        "\n",
        "\n",
        "  def init_hidden(self,batch_size):\n",
        "    change= next(self.parameters()).data\n",
        "    hidden = (change.new(self.n_layers, batch_size, self.hidden).zero_(),\n",
        "      change.new(self.n_layers, batch_size, self.hidden).zero_())\n",
        "    return hidden\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8aCUqNzgScn",
        "colab_type": "text"
      },
      "source": [
        "# **TRAINING THE** **MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK1oXnjQ0icw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model,data,batch_size,epochs,lr,seq_length,val_frac,print_every,clip=5):\n",
        "\n",
        "  model.train()\n",
        "  count=0\n",
        "  n_char=len(model.char)\n",
        "  optimizer=torch.optim.Adam(model.parameters(),lr=lr)\n",
        "  criterian=nn.CrossEntropyLoss()\n",
        "  val_indx=int(len(data)*(1-val_frac))\n",
        "  data,val_data=data[:val_indx],data[val_indx:]\n",
        "\n",
        "\n",
        "\n",
        "  for i in range(epochs):\n",
        "    h = model.init_hidden(batch_size)\n",
        "    \n",
        "\n",
        "\n",
        "    for x,y in get_batches(data,batch_size,seq_length):\n",
        "      count=count+1\n",
        "      \n",
        "      \n",
        "      x= one_hot_encod(x,n_char)\n",
        "      inputs,targets = torch.from_numpy(x),torch.from_numpy(y)\n",
        "      h=tuple([each.data for each in h])\n",
        "      #print(h)\n",
        "\n",
        "      model.zero_grad()\n",
        "\n",
        "\n",
        "      outputs,h = model(inputs,h)\n",
        "      \n",
        "      \n",
        "      loss=criterian(outputs, targets.view(batch_size*seq_length).long())\n",
        "      loss.backward()\n",
        "      nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "      optimizer.step()\n",
        "      if count % print_every == 0:\n",
        "        print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
        "                      \"Step: {}...\".format(count),\n",
        "                      \"Loss: {:.4f}...\".format(loss.item()))\n",
        "                      #Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
        "\n",
        "\n",
        "      '''if count % print_every == 0:\n",
        "        val_h = model.init_hidden(batch_size)\n",
        "        val_losses = []\n",
        "        model.eval()\n",
        "        for x, y in get_batches(val_data, batch_size, seq_length):\n",
        "\n",
        "                    \n",
        "          x = one_hot_encod(x, n_char)\n",
        "          x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
        "                    \n",
        "               \n",
        "          val_h = tuple([each.data for each in val_h])\n",
        "                    \n",
        "          inputs, targets = x, y\n",
        "          \n",
        "          output, val_h = model(inputs, val_h)\n",
        "          #print(targets.view(batch_size*seq_length))\n",
        "          \n",
        "          \n",
        "          val_loss = criterian(output, targets.view(batch_size*seq_length).long())\n",
        "                \n",
        "          val_losses.append(val_loss.item())\n",
        "                \n",
        "          model.train() # reset to train mode after iterationg through validation data\n",
        "      if count % print_every == 0:\n",
        "        print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
        "                      \"Step: {}...\".format(count),\n",
        "                      \"Loss: {:.4f}...\".format(loss.item()))\n",
        "                      #Val Loss: {:.4f}\".format(np.mean(val_losses)))'''\n",
        "\n",
        "      \n",
        "\n",
        "      \n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-ePdkmBr5xd",
        "colab_type": "code",
        "outputId": "38c07c65-6f52-4cb1-f669-d3aaf3b1d868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "n_hidden=512\n",
        "n_layers=2\n",
        "\n",
        "model = RNN(char, n_hidden, n_layers)\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN(\n",
            "  (lstm): LSTM(83, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=512, out_features=83, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwrUbV0isOGb",
        "colab_type": "code",
        "outputId": "cae4d982-4a1f-4a68-b1ff-6480123b963e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "batch_size = 128\n",
        "seq_length = 100\n",
        "n_epochs = 2\n",
        "# train the model\n",
        "train(model, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10,val_frac=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/2... Step: 10... Loss: 3.2618...\n",
            "Epoch: 1/2... Step: 20... Loss: 3.1546...\n",
            "Epoch: 1/2... Step: 30... Loss: 3.1419...\n",
            "Epoch: 1/2... Step: 40... Loss: 3.1118...\n",
            "Epoch: 1/2... Step: 50... Loss: 3.1422...\n",
            "Epoch: 1/2... Step: 60... Loss: 3.1143...\n",
            "Epoch: 1/2... Step: 70... Loss: 3.1029...\n",
            "Epoch: 1/2... Step: 80... Loss: 3.1030...\n",
            "Epoch: 1/2... Step: 90... Loss: 3.0843...\n",
            "Epoch: 1/2... Step: 100... Loss: 3.0041...\n",
            "Epoch: 1/2... Step: 110... Loss: 2.9673...\n",
            "Epoch: 1/2... Step: 120... Loss: 2.8302...\n",
            "Epoch: 1/2... Step: 130... Loss: 2.7813...\n",
            "Epoch: 2/2... Step: 140... Loss: 2.6935...\n",
            "Epoch: 2/2... Step: 150... Loss: 2.6126...\n",
            "Epoch: 2/2... Step: 160... Loss: 2.5398...\n",
            "Epoch: 2/2... Step: 170... Loss: 2.4715...\n",
            "Epoch: 2/2... Step: 180... Loss: 2.4388...\n",
            "Epoch: 2/2... Step: 190... Loss: 2.3965...\n",
            "Epoch: 2/2... Step: 200... Loss: 2.3800...\n",
            "Epoch: 2/2... Step: 210... Loss: 2.3533...\n",
            "Epoch: 2/2... Step: 220... Loss: 2.3090...\n",
            "Epoch: 2/2... Step: 230... Loss: 2.3007...\n",
            "Epoch: 2/2... Step: 240... Loss: 2.2846...\n",
            "Epoch: 2/2... Step: 250... Loss: 2.2171...\n",
            "Epoch: 2/2... Step: 260... Loss: 2.1890...\n",
            "Epoch: 2/2... Step: 270... Loss: 2.1995...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvVqm1tntaxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = 'rnn_20_epoch.net'\n",
        "\n",
        "checkpoint = {'n_hidden': model.hidden,\n",
        "              'n_layers': model.n_layers,\n",
        "              'state_dict': model.state_dict(),\n",
        "              'tokens': model.char}\n",
        "\n",
        "with open(model_name, 'wb') as f:\n",
        "    torch.save(checkpoint, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQOogmJv4gfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Learning (data,batch_size,seq_length):\n",
        "  n_char=len(model.char)\n",
        "  count=0\n",
        "  for x, y in get_batches(data, batch_size, seq_length):\n",
        "    x = one_hot_encod(x, n_char)\n",
        "    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
        "    count=count+1                \n",
        "               \n",
        "    #val_h = tuple([each.data for each in val_h])\n",
        "                    \n",
        "    inputs, targets = x, y\n",
        "    #from torch import tensor\n",
        "    print(x.size())\n",
        "    print(y.size())\n",
        "    #print(len(y))\n",
        "    p=targets.flatten()\n",
        "    print(p.size())\n",
        "    print(count)      \n",
        "    #output, val_h = model(inputs, val_h)\n",
        "    #print(len(targets.view(batch_size*seq_length)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0Pj2V6AVwhW",
        "colab_type": "code",
        "outputId": "8f47d008-7a94-4f1c-c760-d972879b3ead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "Learning (data=encoded,batch_size=128,seq_length=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "1\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "2\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "3\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "4\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "5\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "6\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "7\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "8\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "9\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "10\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "11\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "12\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "13\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "14\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "15\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "16\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "17\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "18\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "19\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "20\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "21\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "22\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "23\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "24\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "25\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "26\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "27\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "28\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "29\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "30\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "31\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "32\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "33\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "34\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "35\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "36\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "37\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "38\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "39\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "40\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "41\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "42\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "43\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "44\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "45\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "46\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "47\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "48\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "49\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "50\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "51\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "52\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "53\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "54\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "55\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "56\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "57\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "58\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "59\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "60\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "61\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "62\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "63\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "64\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "65\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "66\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "67\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "68\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "69\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "70\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "71\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "72\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "73\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "74\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "75\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "76\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "77\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "78\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "79\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "80\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "81\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "82\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "83\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "84\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "85\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "86\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "87\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "88\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "89\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "90\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "91\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "92\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "93\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "94\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "95\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "96\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "97\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "98\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "99\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "100\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "101\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "102\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "103\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "104\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "105\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "106\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "107\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "108\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "109\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "110\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "111\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "112\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "113\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "114\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "115\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "116\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "117\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "118\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "119\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "120\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "121\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "122\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "123\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "124\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "125\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "126\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "127\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "128\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "129\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "130\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "131\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "132\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "133\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "134\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "135\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "136\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "137\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "138\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "139\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "140\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "141\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "142\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "143\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "144\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "145\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "146\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "147\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "148\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "149\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "150\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "151\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "152\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "153\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "154\n",
            "torch.Size([128, 100, 83])\n",
            "torch.Size([128, 100])\n",
            "torch.Size([12800])\n",
            "155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPZqmbtbWGKq",
        "colab_type": "code",
        "outputId": "c17e3d33-36e1-47e2-e12b-837ebada6251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "z = 155*128*100\n",
        "print(z)\n",
        "print(len(encoded))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1984000\n",
            "1985223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZELtG2hgmn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}